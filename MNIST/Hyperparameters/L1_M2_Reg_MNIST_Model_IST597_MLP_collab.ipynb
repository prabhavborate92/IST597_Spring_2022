{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "L1_M2_Reg_MNIST_Model_IST597_MLP_collab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prabhavborate92/IST597_Spring_2022/blob/main/MNIST/Hyperparameters/L1_M2_Reg_MNIST_Model_IST597_MLP_collab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71kdFp0QgF4K"
      },
      "source": [
        "# IST597:- Multi-Layer Perceptron Assignment :- pgb5080@psu.edu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2yHcl5xgPV1"
      },
      "source": [
        "## Load the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DPwxLR2gSLC"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from math import sqrt\n",
        "from sklearn.model_selection import train_test_split\n",
        "np.random.seed(5080)\n",
        "tf.random.set_seed(5080)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Dk_S2TMg_6_"
      },
      "source": [
        "## Load MNIST Data\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load Data\n",
        "mnist = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "3GkQ7thks4ZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3031b6f4-7150-40ad-8a18-5018b3ef2b7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Data\n",
        "\n",
        "train_ratio = 0.80\n",
        "validation_ratio = 0.10\n",
        "test_ratio = 0.10\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist\n",
        "\n",
        "X = np.concatenate([X_train, X_test])\n",
        "y = np.concatenate([y_train, y_test])\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=(1-train_ratio))\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=((test_ratio/(validation_ratio+test_ratio))))\n"
      ],
      "metadata": {
        "id": "ZxaBc7LW9bDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display Sample Data\n",
        "\n",
        "indices = list(np.random.randint(X_train.shape[0],size=3))\n",
        "for i in range(3):\n",
        "    plt.subplot(1,3,i+1)\n",
        "    plt.imshow(X_train[indices[i]].reshape(28,28), cmap='gray', interpolation='none')\n",
        "    plt.title(\"Index {} Class {}\".format(indices[i], y_train[indices[i]]))\n",
        "    plt.tight_layout()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "J0U2CSfG6Wwf",
        "outputId": "0a3a651c-9315-4262-9c1e-a872130d2fa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Size\n",
        "print(\"X_train Size:\" + str(X_train.shape))\n",
        "print(\"X_val Size:\" + str(X_val.shape))\n",
        "print(\"X_test Size:\" + str(X_test.shape))\n",
        "\n",
        "print(\"y_train Size:\" + str(y_train.shape))\n",
        "print(\"y_val Size:\" + str(y_val.shape))\n",
        "print(\"y_test Size:\" + str(y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVQXQ1vyBNEc",
        "outputId": "846eb1bb-6235-4724-8ab3-bc3a27f2e3bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train Size:(56000, 28, 28)\n",
            "X_val Size:(7000, 28, 28)\n",
            "X_test Size:(7000, 28, 28)\n",
            "y_train Size:(56000,)\n",
            "y_val Size:(7000,)\n",
            "y_test Size:(7000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape Input Data\n",
        "X_train = np.reshape(X_train,(X_train.shape[0],X_train.shape[1]*X_train.shape[2]))\n",
        "X_val = np.reshape(X_val,(X_val.shape[0],X_val.shape[1]*X_val.shape[2]))\n",
        "X_test = np.reshape(X_test,(X_test.shape[0],X_test.shape[1]*X_test.shape[2]))\n",
        "\n",
        "print(\"X_train Size:\" + str(X_train.shape))\n",
        "print(\"X_val Size:\" + str(X_val.shape))\n",
        "print(\"X_test Size:\" + str(X_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2Lrm4QtHGJP",
        "outputId": "d9c43a87-7e2a-408a-b6c2-0abfc2b749bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train Size:(56000, 784)\n",
            "X_val Size:(7000, 784)\n",
            "X_test Size:(7000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rescale data \n",
        "X_train=tf.cast(X_train,dtype=tf.float32)\n",
        "X_val=tf.cast(X_val,dtype=tf.float32)\n",
        "X_test=tf.cast(X_test,dtype=tf.float32)\n",
        "X_train=X_train/255.0\n",
        "X_val=X_val/255.0\n",
        "X_test=X_test/255.0"
      ],
      "metadata": {
        "id": "nnLQo1pGQq5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Details of input & output data\n",
        "\n",
        "print(\"Training input data range: \\nFrom \" + str(np.min(X_train)) + \" to \" + str(np.max(X_train)))\n",
        "print(\"Validation input data range: \\nFrom \" + str(np.min(X_val)) + \" to \" + str(np.max(X_val)))\n",
        "print(\"Testing input data range: \\nFrom \" + str(np.min(X_test)) + \" to \" + str(np.max(X_test)))\n",
        "\n",
        "print(\"\\nTraining target data: \")\n",
        "print(set(list(y_train)))\n",
        "\n",
        "print(\"\\nValidation target data: \")\n",
        "print(set(list(y_val)))\n",
        "\n",
        "print(\"\\nTesting target data: \")\n",
        "print(set(list(y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsUMeChpIx3-",
        "outputId": "5879fb84-8127-4bc3-df1b-320f8b422167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training input data range: \n",
            "From 0.0 to 1.0\n",
            "Validation input data range: \n",
            "From 0.0 to 1.0\n",
            "Testing input data range: \n",
            "From 0.0 to 1.0\n",
            "\n",
            "Training target data: \n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
            "\n",
            "Validation target data: \n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
            "\n",
            "Testing target data: \n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Data\n",
        "size_input = X_train.shape[1] # Input size\n",
        "Input_layer_size =  X_train.shape[1] # Input size\n",
        "size_hidden1 = 512 # Hidden neuron in first layer\n",
        "size_hidden2 = 256 # Hidden neuron in second layer\n",
        "size_output = 10 # Number of classes (target)\n",
        "\n",
        "y_train=tf.keras.utils.to_categorical(y_train,size_output)\n",
        "y_val=tf.keras.utils.to_categorical(y_val,size_output)\n",
        "y_test=tf.keras.utils.to_categorical(y_test,size_output)"
      ],
      "metadata": {
        "id": "3_KwZ38eyNQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print \n",
        "\n",
        "print(\"y_train: \",y_train)\n",
        "print(\"y_val: \",y_val)\n",
        "print(\"y_test: \",y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAlVM_Mo2YKV",
        "outputId": "d889c128-b761-4e69-eae1-1c1d823b59b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train:  [[0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]]\n",
            "y_val:  [[0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 1. ... 0. 0. 0.]]\n",
            "y_test:  [[0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aigqKFFF5BM2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2e3a44f-3c31-4e3d-c31f-a56107361bae"
      },
      "source": [
        "# Split dataset into batches\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(16)\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(2)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(2)\n",
        "print(\"train_ds:\",train_ds)\n",
        "print(\"train_ds:\",val_ds)\n",
        "print(\"test_ds:\",test_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_ds: <BatchDataset shapes: ((None, 784), (None, 10)), types: (tf.float32, tf.float32)>\n",
            "train_ds: <BatchDataset shapes: ((None, 784), (None, 10)), types: (tf.float32, tf.float32)>\n",
            "test_ds: <BatchDataset shapes: ((None, 784), (None, 10)), types: (tf.float32, tf.float32)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb4hOoVbnzSJ"
      },
      "source": [
        "## Build MLP using Eager Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ht9_qpYipgHw"
      },
      "source": [
        "# Define class to build mlp model\n",
        "class MLP(object):\n",
        "  def __init__(self, Input_layer_size, size_input, size_hidden1, size_hidden2, size_output, device=None):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden: int, size of hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input, self.Input_layer_size, self.size_hidden1, self.size_hidden2, self.size_output, self.device =\\\n",
        "    size_input, Input_layer_size, size_hidden1, size_hidden2, size_output, device\n",
        "    \n",
        "    # Initialize weights for inputs\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.Input_layer_size]))\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.Input_layer_size]))\n",
        "\n",
        "    # Initialize weights between input layer and hidden layer 1\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.Input_layer_size, self.size_hidden1]))\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_hidden1]))\n",
        "\n",
        "    # Initialize weights between hidden layer 1 and hidden layer 2\n",
        "    self.W3 = tf.Variable(tf.random.normal([self.size_hidden1, self.size_hidden2]))\n",
        "    # Initialize biases for hidden2 layer\n",
        "    self.b3 = tf.Variable(tf.random.normal([1, self.size_hidden2]))\n",
        "\n",
        "     # Initialize weights between hidden layer 2 and output layer\n",
        "    self.W4 = tf.Variable(tf.random.normal([self.size_hidden2, self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b4 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.W4, self.b1, self.b2, self.b3, self.b4]\n",
        "    \n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "  \n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    return tf.losses.categorical_crossentropy(y_true_tf, y_pred_tf)\n",
        "  \n",
        "  def backward(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      reg = (tf.reduce_sum(tf.abs(self.W1)) + tf.reduce_sum(tf.abs(self.W2)) + tf.reduce_sum(tf.abs(self.W3))+tf.reduce_sum(tf.abs(self.W4))) # L1 penalty \n",
        "      current_loss = self.loss(predicted, y_train) + 0.05*reg\n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "        \n",
        "        \n",
        "  def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    # Compute values in input\n",
        "    what1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat1 = tf.nn.relu(what1)\n",
        "    # Compute values in hidden layer 1\n",
        "    what2 = tf.matmul(hhat1, self.W2) + self.b2\n",
        "    hhat2 = tf.nn.relu(what2)\n",
        "    # Compute values in hidden layer 2\n",
        "    what3 = tf.matmul(hhat2, self.W3) + self.b3\n",
        "    hhat3 = tf.nn.relu(what3)\n",
        "    # Compute output\n",
        "    output = tf.matmul(hhat3, self.W4) + self.b4\n",
        "    output = tf.nn.softmax(output)\n",
        "    return output\n",
        "  \n",
        " # Calculate standard error\n",
        "  def stderr(self,y_pred):\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    std_dev = np.std(y_pred_tf) #Calculates standard deviation\n",
        "    std_err = std_dev/sqrt(len(y_pred_tf))\n",
        "    return std_err \n",
        "\n",
        " # Calculate variance error\n",
        "  def var(self,y_pred):\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    std_dev = np.std(y_pred_tf) #Calculates standard deviation\n",
        "    variance = (std_dev**2) # calculate variance\n",
        "    return variance     \n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUDFOuNk618X"
      },
      "source": [
        "## Train Model:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set number of epochs\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "# Initialize model using CPU\n",
        "mlp_on_cpu = MLP(size_input, Input_layer_size, size_hidden1, size_hidden2, size_output, device='cpu')\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(5080)).batch(20)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_cpu.forward(inputs)\n",
        "    loss_total = loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_cpu.loss(preds, outputs)\n",
        "    mlp_on_cpu.backward(inputs, outputs)\n",
        "  print('Number of Epoch = {} - Average Cross Entropy:= {}'.format(epoch + 1, np.sum(loss_total)/X_train.shape[0]))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuJhbBmPF_gt",
        "outputId": "3cac5407-854b-430a-86cc-1accad5bed6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Average Cross Entropy:= 11.1299140625\n",
            "Number of Epoch = 2 - Average Cross Entropy:= 2.3145181361607143\n",
            "Number of Epoch = 3 - Average Cross Entropy:= 2.3188929966517855\n",
            "Number of Epoch = 4 - Average Cross Entropy:= 2.3161636439732143\n",
            "Number of Epoch = 5 - Average Cross Entropy:= 2.315559151785714\n",
            "Number of Epoch = 6 - Average Cross Entropy:= 2.314389090401786\n",
            "Number of Epoch = 7 - Average Cross Entropy:= 2.313458426339286\n",
            "Number of Epoch = 8 - Average Cross Entropy:= 2.313257393973214\n",
            "Number of Epoch = 9 - Average Cross Entropy:= 2.3128168247767857\n",
            "Number of Epoch = 10 - Average Cross Entropy:= 2.3122816685267855\n",
            "\n",
            "Total time taken (in seconds): 1258.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXe-2MENCOjq"
      },
      "source": [
        "## One Step Inference: Validation\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ac6c501-0f96-4cb9-a412-aa1ac1c3c848",
        "id": "CQoIf58OTRTE"
      },
      "source": [
        "# Initialize\n",
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "acc_preds = tf.Variable(0,dtype=tf.float32)\n",
        "acc = tf.Variable(0, dtype=tf.float32)\n",
        "\n",
        "# Calculate\n",
        "for inputs, outputs in val_ds:\n",
        "\n",
        "  preds = mlp_on_cpu.forward(inputs) # Prediction\n",
        "  test_loss_total = test_loss_total + mlp_on_cpu.loss(preds,outputs) # Loss\n",
        "  standard_error = mlp_on_cpu.stderr(preds) # Standard error\n",
        "  Variance = mlp_on_cpu.var(preds) # Variance\n",
        "\n",
        "  for i in range(preds.shape[0]):\n",
        "    if tf.argmax(preds[i])==tf.argmax(outputs[i]):\n",
        "      acc_preds = acc_preds + 1.0\n",
        "acc = (acc_preds/X_test.shape[0])*100.0\n",
        "print('Inference 1st')\n",
        "print('Val Loss: {:.4f}'.format(np.sum(test_loss_total.numpy())/X_train.shape[0]))\n",
        "print('Accuracy: {:.4f}'.format(acc))\n",
        "print('Standard Error: {:.4f}'.format(standard_error))\n",
        "print('Variance: {:.4f}'.format(Variance))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference 1st\n",
            "Val Loss: 0.2904\n",
            "Accuracy: 9.8857\n",
            "Standard Error: 0.0145\n",
            "Variance: 0.0004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One Step Inference: Testing"
      ],
      "metadata": {
        "id": "IoYcVvKETNpD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKxWn7CNDVN5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a02af47-3811-4049-a9cf-9bf938ece3d9"
      },
      "source": [
        "# Initialize\n",
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "acc_preds = tf.Variable(0,dtype=tf.float32)\n",
        "acc = tf.Variable(0, dtype=tf.float32)\n",
        "\n",
        "# Calculate\n",
        "for inputs, outputs in test_ds:\n",
        "\n",
        "  preds = mlp_on_cpu.forward(inputs) # Prediction\n",
        "  test_loss_total = test_loss_total + mlp_on_cpu.loss(preds,outputs) # Loss\n",
        "  standard_error = mlp_on_cpu.stderr(preds) # Standard error\n",
        "  Variance = mlp_on_cpu.var(preds) # Variance\n",
        "\n",
        "  for i in range(preds.shape[0]):\n",
        "    if tf.argmax(preds[i])==tf.argmax(outputs[i]):\n",
        "      acc_preds = acc_preds + 1.0\n",
        "acc = (acc_preds/X_test.shape[0])*100.0\n",
        "print('Inference 1st')\n",
        "print('Test Loss: {:.4f}'.format(np.sum(test_loss_total.numpy())/X_train.shape[0]))\n",
        "print('Accuracy: {:.4f}'.format(acc))\n",
        "print('Standard Error: {:.4f}'.format(standard_error))\n",
        "print('Variance: {:.4f}'.format(Variance))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference 1st\n",
            "Test Loss: 0.2905\n",
            "Accuracy: 9.8429\n",
            "Standard Error: 0.0145\n",
            "Variance: 0.0004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_gpODqbnTVKk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}