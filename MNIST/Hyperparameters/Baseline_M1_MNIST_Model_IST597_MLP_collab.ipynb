{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline_M1_MNIST_Model_IST597_MLP_collab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prabhavborate92/IST597_Spring_2022/blob/main/MNIST/Hyperparameters/Baseline_M1_MNIST_Model_IST597_MLP_collab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71kdFp0QgF4K"
      },
      "source": [
        "# IST597:- Multi-Layer Perceptron Assignment :- pgb5080@psu.edu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2yHcl5xgPV1"
      },
      "source": [
        "## Load the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DPwxLR2gSLC"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from math import sqrt\n",
        "from sklearn.model_selection import train_test_split\n",
        "np.random.seed(5080)\n",
        "tf.random.set_seed(5080)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Dk_S2TMg_6_"
      },
      "source": [
        "## Load MNIST Data\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load Data\n",
        "mnist = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "3GkQ7thks4ZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Data\n",
        "\n",
        "train_ratio = 0.80\n",
        "validation_ratio = 0.10\n",
        "test_ratio = 0.10\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist\n",
        "\n",
        "X = np.concatenate([X_train, X_test])\n",
        "y = np.concatenate([y_train, y_test])\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=(1-train_ratio))\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=((test_ratio/(validation_ratio+test_ratio))))\n"
      ],
      "metadata": {
        "id": "ZxaBc7LW9bDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display Sample Data\n",
        "\n",
        "indices = list(np.random.randint(X_train.shape[0],size=3))\n",
        "for i in range(3):\n",
        "    plt.subplot(1,3,i+1)\n",
        "    plt.imshow(X_train[indices[i]].reshape(28,28), cmap='gray', interpolation='none')\n",
        "    plt.title(\"Index {} Class {}\".format(indices[i], y_train[indices[i]]))\n",
        "    plt.tight_layout()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "J0U2CSfG6Wwf",
        "outputId": "c45fa6aa-a9a7-4fe3-c984-ce5744e35318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Size\n",
        "print(\"X_train Size:\" + str(X_train.shape))\n",
        "print(\"X_val Size:\" + str(X_val.shape))\n",
        "print(\"X_test Size:\" + str(X_test.shape))\n",
        "\n",
        "print(\"y_train Size:\" + str(y_train.shape))\n",
        "print(\"y_val Size:\" + str(y_val.shape))\n",
        "print(\"y_test Size:\" + str(y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVQXQ1vyBNEc",
        "outputId": "02ad1ab4-e1d8-402c-b8b0-6d012717af63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train Size:(56000, 28, 28)\n",
            "X_val Size:(7000, 28, 28)\n",
            "X_test Size:(7000, 28, 28)\n",
            "y_train Size:(56000,)\n",
            "y_val Size:(7000,)\n",
            "y_test Size:(7000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape Input Data\n",
        "X_train = np.reshape(X_train,(X_train.shape[0],X_train.shape[1]*X_train.shape[2]))\n",
        "X_val = np.reshape(X_val,(X_val.shape[0],X_val.shape[1]*X_val.shape[2]))\n",
        "X_test = np.reshape(X_test,(X_test.shape[0],X_test.shape[1]*X_test.shape[2]))\n",
        "\n",
        "print(\"X_train Size:\" + str(X_train.shape))\n",
        "print(\"X_val Size:\" + str(X_val.shape))\n",
        "print(\"X_test Size:\" + str(X_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2Lrm4QtHGJP",
        "outputId": "e5263285-684f-4a94-ed7a-75ddbaa79752"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train Size:(56000, 784)\n",
            "X_val Size:(7000, 784)\n",
            "X_test Size:(7000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rescale data \n",
        "X_train=tf.cast(X_train,dtype=tf.float32)\n",
        "X_val=tf.cast(X_val,dtype=tf.float32)\n",
        "X_test=tf.cast(X_test,dtype=tf.float32)\n",
        "X_train=X_train/255.0\n",
        "X_val=X_val/255.0\n",
        "X_test=X_test/255.0"
      ],
      "metadata": {
        "id": "nnLQo1pGQq5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Details of input & output data\n",
        "\n",
        "print(\"Training input data range: \\nFrom \" + str(np.min(X_train)) + \" to \" + str(np.max(X_train)))\n",
        "print(\"Validation input data range: \\nFrom \" + str(np.min(X_val)) + \" to \" + str(np.max(X_val)))\n",
        "print(\"Testing input data range: \\nFrom \" + str(np.min(X_test)) + \" to \" + str(np.max(X_test)))\n",
        "\n",
        "print(\"\\nTraining target data: \")\n",
        "print(set(list(y_train)))\n",
        "\n",
        "print(\"\\nValidation target data: \")\n",
        "print(set(list(y_val)))\n",
        "\n",
        "print(\"\\nTesting target data: \")\n",
        "print(set(list(y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsUMeChpIx3-",
        "outputId": "5e901f48-255f-436b-fa83-1692446d3482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training input data range: \n",
            "From 0.0 to 1.0\n",
            "Validation input data range: \n",
            "From 0.0 to 1.0\n",
            "Testing input data range: \n",
            "From 0.0 to 1.0\n",
            "\n",
            "Training target data: \n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
            "\n",
            "Validation target data: \n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
            "\n",
            "Testing target data: \n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Data\n",
        "size_input = X_train.shape[1] # Input size\n",
        "Input_layer_size =  X_train.shape[1] # Input size\n",
        "size_hidden1 = 512 # Hidden neuron in first layer\n",
        "size_hidden2 = 256 # Hidden neuron in second layer\n",
        "size_output = 10 # Number of classes (target)\n",
        "\n",
        "y_train=tf.keras.utils.to_categorical(y_train,size_output)\n",
        "y_val=tf.keras.utils.to_categorical(y_val,size_output)\n",
        "y_test=tf.keras.utils.to_categorical(y_test,size_output)"
      ],
      "metadata": {
        "id": "3_KwZ38eyNQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print \n",
        "\n",
        "print(\"y_train: \",y_train)\n",
        "print(\"y_val: \",y_val)\n",
        "print(\"y_test: \",y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAlVM_Mo2YKV",
        "outputId": "91eaa30f-3987-4f56-ba84-8fad810c3389"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train:  [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "y_val:  [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]]\n",
            "y_test:  [[0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aigqKFFF5BM2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2063de15-4ae8-43f4-d01e-c5bcb5b75ca9"
      },
      "source": [
        "# Split dataset into batches\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(16)\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(2)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(2)\n",
        "print(\"train_ds:\",train_ds)\n",
        "print(\"train_ds:\",val_ds)\n",
        "print(\"test_ds:\",test_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_ds: <BatchDataset shapes: ((None, 784), (None, 10)), types: (tf.float32, tf.float32)>\n",
            "train_ds: <BatchDataset shapes: ((None, 784), (None, 10)), types: (tf.float32, tf.float32)>\n",
            "test_ds: <BatchDataset shapes: ((None, 784), (None, 10)), types: (tf.float32, tf.float32)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb4hOoVbnzSJ"
      },
      "source": [
        "## Build MLP using Eager Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ht9_qpYipgHw"
      },
      "source": [
        "# Define class to build mlp model\n",
        "class MLP(object):\n",
        "  def __init__(self, Input_layer_size, size_input, size_hidden1, size_hidden2, size_output, device=None):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden: int, size of hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input, self.Input_layer_size, self.size_hidden1, self.size_hidden2, self.size_output, self.device =\\\n",
        "    size_input, Input_layer_size, size_hidden1, size_hidden2, size_output, device\n",
        "    \n",
        "    # Initialize weights for inputs\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.Input_layer_size]))\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.Input_layer_size]))\n",
        "\n",
        "    # Initialize weights between input layer and hidden layer 1\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.Input_layer_size, self.size_hidden1]))\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_hidden1]))\n",
        "\n",
        "    # Initialize weights between hidden layer 1 and hidden layer 2\n",
        "    self.W3 = tf.Variable(tf.random.normal([self.size_hidden1, self.size_hidden2]))\n",
        "    # Initialize biases for hidden2 layer\n",
        "    self.b3 = tf.Variable(tf.random.normal([1, self.size_hidden2]))\n",
        "\n",
        "     # Initialize weights between hidden layer 2 and output layer\n",
        "    self.W4 = tf.Variable(tf.random.normal([self.size_hidden2, self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b4 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.W4, self.b1, self.b2, self.b3, self.b4]\n",
        "    \n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "  \n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    return tf.losses.categorical_crossentropy(y_true_tf, y_pred_tf)\n",
        "  \n",
        "  def backward(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      # reg = (tf.reduce_sum(tf.square(self.W1)) + tf.reduce_sum(tf.square(self.W2)) + tf.reduce_sum(tf.square(self.W3))) # L2 penalty \n",
        "      # current_loss = self.loss(predicted, y_train) + 0.05*reg\n",
        "      current_loss = self.loss(predicted, y_train) \n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "        \n",
        "        \n",
        "  def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    # Compute values in input\n",
        "    what1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat1 = tf.nn.relu(what1)\n",
        "    # Compute values in hidden layer 1\n",
        "    what2 = tf.matmul(hhat1, self.W2) + self.b2\n",
        "    hhat2 = tf.nn.relu(what2)\n",
        "    # Compute values in hidden layer 2\n",
        "    what3 = tf.matmul(hhat2, self.W3) + self.b3\n",
        "    hhat3 = tf.nn.relu(what3)\n",
        "    # Compute output\n",
        "    output = tf.matmul(hhat3, self.W4) + self.b4\n",
        "    output = tf.nn.softmax(output)\n",
        "    return output\n",
        "  \n",
        " # Calculate standard error\n",
        "  def stderr(self,y_pred):\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    std_dev = np.std(y_pred_tf) #Calculates standard deviation\n",
        "    std_err = std_dev/sqrt(len(y_pred_tf))\n",
        "    return std_err \n",
        "\n",
        " # Calculate variance error\n",
        "  def var(self,y_pred):\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    std_dev = np.std(y_pred_tf) #Calculates standard deviation\n",
        "    variance = (std_dev**2) # calculate variance\n",
        "    return variance     \n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUDFOuNk618X"
      },
      "source": [
        "## Train Model:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set number of epochs\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "# Initialize model using CPU\n",
        "mlp_on_cpu = MLP(size_input, Input_layer_size, size_hidden1, size_hidden2, size_output, device='cpu')\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(5080)).batch(20)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_cpu.forward(inputs)\n",
        "    loss_total = loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_cpu.loss(preds, outputs)\n",
        "    mlp_on_cpu.backward(inputs, outputs)\n",
        "  print('Number of Epoch = {} - Average Cross Entropy:= {}'.format(epoch + 1, np.sum(loss_total)/X_train.shape[0]))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuJhbBmPF_gt",
        "outputId": "fdf75110-7b67-4987-bf8d-5c67679f1d84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Average Cross Entropy:= 14.758154017857143\n",
            "Number of Epoch = 2 - Average Cross Entropy:= 14.660082589285715\n",
            "Number of Epoch = 3 - Average Cross Entropy:= 14.660083705357144\n",
            "Number of Epoch = 4 - Average Cross Entropy:= 14.660082589285715\n",
            "Number of Epoch = 5 - Average Cross Entropy:= 14.660083705357144\n",
            "Number of Epoch = 6 - Average Cross Entropy:= 14.660083705357144\n",
            "Number of Epoch = 7 - Average Cross Entropy:= 14.660082589285715\n",
            "Number of Epoch = 8 - Average Cross Entropy:= 14.66008482142857\n",
            "Number of Epoch = 9 - Average Cross Entropy:= 14.660083705357144\n",
            "Number of Epoch = 10 - Average Cross Entropy:= 14.660083705357144\n",
            "\n",
            "Total time taken (in seconds): 736.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXe-2MENCOjq"
      },
      "source": [
        "## One Step Inference: Validation\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecdd01dd-6f6b-4e3e-db45-a2244964be3b",
        "id": "CQoIf58OTRTE"
      },
      "source": [
        "# Initialize\n",
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "acc_preds = tf.Variable(0,dtype=tf.float32)\n",
        "acc = tf.Variable(0, dtype=tf.float32)\n",
        "\n",
        "# Calculate\n",
        "for inputs, outputs in val_ds:\n",
        "\n",
        "  preds = mlp_on_cpu.forward(inputs) # Prediction\n",
        "  test_loss_total = test_loss_total + mlp_on_cpu.loss(preds,outputs) # Loss\n",
        "  standard_error = mlp_on_cpu.stderr(preds) # Standard error\n",
        "  Variance = mlp_on_cpu.var(preds) # Variance\n",
        "\n",
        "  for i in range(preds.shape[0]):\n",
        "    if tf.argmax(preds[i])==tf.argmax(outputs[i]):\n",
        "      acc_preds = acc_preds + 1.0\n",
        "acc = (acc_preds/X_test.shape[0])*100.0\n",
        "print('Inference 1st')\n",
        "print('Test MSE: {:.4f}'.format(np.sum(test_loss_total.numpy())/X_train.shape[0]))\n",
        "print('Accuracy: {:.4f}'.format(acc))\n",
        "print('Standard Error: {:.4f}'.format(standard_error))\n",
        "print('Variance: {:.4f}'.format(Variance))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference 1st\n",
            "Test MSE: 1.8342\n",
            "Accuracy: 8.9571\n",
            "Standard Error: 0.2121\n",
            "Variance: 0.0900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One Step Inference: Testing"
      ],
      "metadata": {
        "id": "IoYcVvKETNpD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKxWn7CNDVN5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7ac6334-df0f-4c10-fb8c-5d00ce38d178"
      },
      "source": [
        "# Initialize\n",
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "acc_preds = tf.Variable(0,dtype=tf.float32)\n",
        "acc = tf.Variable(0, dtype=tf.float32)\n",
        "\n",
        "# Calculate\n",
        "for inputs, outputs in test_ds:\n",
        "\n",
        "  preds = mlp_on_cpu.forward(inputs) # Prediction\n",
        "  test_loss_total = test_loss_total + mlp_on_cpu.loss(preds,outputs) # Loss\n",
        "  standard_error = mlp_on_cpu.stderr(preds) # Standard error\n",
        "  Variance = mlp_on_cpu.var(preds) # Variance\n",
        "\n",
        "  for i in range(preds.shape[0]):\n",
        "    if tf.argmax(preds[i])==tf.argmax(outputs[i]):\n",
        "      acc_preds = acc_preds + 1.0\n",
        "acc = (acc_preds/X_test.shape[0])*100.0\n",
        "print('Inference 1st')\n",
        "print('Test MSE: {:.4f}'.format(np.sum(test_loss_total.numpy())/X_train.shape[0]))\n",
        "print('Accuracy: {:.4f}'.format(acc))\n",
        "print('Standard Error: {:.4f}'.format(standard_error))\n",
        "print('Variance: {:.4f}'.format(Variance))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference 1st\n",
            "Test MSE: 1.8362\n",
            "Accuracy: 8.8571\n",
            "Standard Error: 0.2121\n",
            "Variance: 0.0900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_gpODqbnTVKk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}